{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch, DataLoader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandRotate90,\n",
    "    RandSpatialCrop,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "from monai.transforms import Compose, LoadImage, ScaleIntensity, RandSpatialCrop, RandRotate90, SpatialPad, Resize\n",
    "from monai.data import ArrayDataset, DataLoader\n",
    "from monai.metrics import DiceMetric, MeanIoU, ConfusionMatrixMetric\n",
    "from monai.transforms import Activations, AsDiscrete\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "\n",
    "tempdir = \"/Users/nittin_murthi/Documents/VS_Code/MONAI-UNET/segmentation_data/malignant/\"\n",
    "\n",
    "# Define paths to image and mask directories\n",
    "image_dir = os.path.join(tempdir, \"image\")\n",
    "mask_dir = os.path.join(tempdir, \"mask\")\n",
    "\n",
    "# Read image and mask file paths\n",
    "images = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "masks = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "\n",
    "if len(images) != len(masks):\n",
    "    raise ValueError(\"The number of images and masks must be the same.\")\n",
    "\n",
    "# Print the total number of samples in the dataset\n",
    "total_samples = len(images)\n",
    "print(f\"Total number of samples in the dataset: {total_samples}\")\n",
    "\n",
    "# Verify that images and masks are correctly matched\n",
    "for img_path, mask_path in zip(images, masks):\n",
    "    img_name = os.path.basename(img_path).split('.')[0].replace(\" \", \"\")\n",
    "    mask_name = os.path.basename(mask_path).split('.')[0].replace(\"_mask_merged\", \"\").replace(\" \", \"\")\n",
    "    if img_name != mask_name:\n",
    "        raise ValueError(f\"Image and mask names do not match: {img_name} vs {mask_name}\")\n",
    "    \n",
    "# Define transforms for image and segmentation\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        ScaleIntensity(),\n",
    "        Resize((128, 128)),\n",
    "        RandSpatialCrop((256, 256), random_size=False),\n",
    "        #SpatialPad((128, 128), method='symmetric', mode='constant', constant_values=0),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "    ]\n",
    ")\n",
    "train_masktrans = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True, ensure_channel_first=True),\n",
    "        ScaleIntensity(),\n",
    "        Resize((128, 128)),\n",
    "        RandSpatialCrop((256, 256), random_size=False),\n",
    "        #SpatialPad((128, 128), method='symmetric', mode='constant', constant_values=0),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "    ]\n",
    ")\n",
    "val_imtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "val_masktrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "\n",
    "# Define array dataset, data loader\n",
    "check_ds = ArrayDataset(images, train_imtrans, masks, train_masktrans)\n",
    "check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=True)\n",
    "im, msk = monai.utils.misc.first(check_loader)\n",
    "print(im.shape, msk.shape)\n",
    "\n",
    "# Display some raw images and their corresponding segmentation masks\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        idx = i * 2 + j\n",
    "        axes[i, j].imshow(im[idx].permute(1, 2, 0).cpu().numpy())\n",
    "        axes[i, j].imshow(msk[idx].squeeze().cpu().numpy(), alpha=0.5)\n",
    "        axes[i, j].axis('off')\n",
    "plt.suptitle(\"Raw Images and Segmentation Masks\")\n",
    "plt.show()\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = total_samples - train_size\n",
    "train_images, val_images = images[:train_size], images[train_size:]\n",
    "train_masks, val_masks = masks[:train_size], masks[train_size:]\n",
    "\n",
    "# Create a training data loader\n",
    "train_ds = ArrayDataset(train_images, train_imtrans, train_masks, train_masktrans)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.backends.mps.is_available())\n",
    "\n",
    "# Create a validation data loader\n",
    "val_ds = ArrayDataset(val_images, val_imtrans, val_masks, val_masktrans)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "# Display some augmented images and their corresponding segmentation masks\n",
    "aug_images, aug_masks = next(iter(train_loader))\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        idx = i * 2 + j\n",
    "        axes[i, j].imshow(aug_images[idx].permute(1, 2, 0).cpu().numpy())\n",
    "        axes[i, j].imshow(aug_masks[idx].squeeze().cpu().numpy(), alpha=0.5)\n",
    "        axes[i, j].axis('off')\n",
    "plt.suptitle(\"Augmented Images and Segmentation Masks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "epoch 1/200\n",
      "1/42, train_loss: 0.7695\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(recall, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     72\u001b[0m     recall \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(recall) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(recall)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeanIOU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_iou\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Precision: \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprecision\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Dice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdice\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem(), epoch_len \u001b[38;5;241m*\u001b[39m epoch \u001b[38;5;241m+\u001b[39m step)\n\u001b[1;32m     77\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_mean_dice\u001b[39m\u001b[38;5;124m\"\u001b[39m, dice, epoch_len \u001b[38;5;241m*\u001b[39m epoch \u001b[38;5;241m+\u001b[39m step)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_tensor.py:966\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "# Define the model, loss, and optimizer\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "# Define metrics\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "mean_iou_metric = MeanIoU(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "precision_metric = ConfusionMatrixMetric(include_background=True, metric_name=\"precision\")\n",
    "recall_metric = ConfusionMatrixMetric(include_background=True, metric_name=\"recall\")\n",
    "\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# Start a typical PyTorch training\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = {'dice': [], 'iou': [], 'precision': [], 'recall': []}\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(200):\n",
    "    print(\"-\" * 200)\n",
    "    print(f\"epoch {epoch + 1}/200\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Compute metrics for current batch\n",
    "        outputs_trans = [post_trans(i) for i in outputs]\n",
    "        dice_metric(y_pred=outputs_trans, y=labels)\n",
    "        mean_iou_metric(y_pred=outputs_trans, y=labels)\n",
    "        precision_metric(y_pred=outputs_trans, y=labels)\n",
    "        recall_metric(y_pred=outputs_trans, y=labels)\n",
    "\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Aggregate metrics\n",
    "        dice = dice_metric.aggregate().item()\n",
    "        mean_iou = mean_iou_metric.aggregate().item()\n",
    "        precision = precision_metric.aggregate()\n",
    "        recall = recall_metric.aggregate()\n",
    "\n",
    "        # Reset metrics\n",
    "        dice_metric.reset()\n",
    "        mean_iou_metric.reset()\n",
    "        precision_metric.reset()\n",
    "        recall_metric.reset()\n",
    "\n",
    "        # Ensure to take the mean if it's a list\n",
    "        if isinstance(precision, list):\n",
    "            precision = sum(precision) / len(precision)\n",
    "        if isinstance(recall, list):\n",
    "            recall = sum(recall) / len(recall)\n",
    "        \n",
    "        print(f\"MeanIOU: {mean_iou:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Dice: {dice:.4f}\")\n",
    "\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        writer.add_scalar(\"train_mean_dice\", dice, epoch_len * epoch + step)\n",
    "        writer.add_scalar(\"train_mean_iou\", mean_iou, epoch_len * epoch + step)\n",
    "        writer.add_scalar(\"train_precision\", precision, epoch_len * epoch + step)\n",
    "        writer.add_scalar(\"train_recall\", recall, epoch_len * epoch + step)\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (128, 128)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = monai.inferers.sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in monai.data.decollate_batch(val_outputs)]\n",
    "                \n",
    "                # Compute metrics for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                mean_iou_metric(y_pred=val_outputs, y=val_labels)\n",
    "                precision_metric(y_pred=val_outputs, y=val_labels)\n",
    "                recall_metric(y_pred=val_outputs, y=val_labels)\n",
    "            \n",
    "            # Aggregate the final mean metric results\n",
    "            dice = dice_metric.aggregate().item()\n",
    "            mean_iou = mean_iou_metric.aggregate().item()\n",
    "            precision = precision_metric.aggregate()\n",
    "            recall = recall_metric.aggregate()\n",
    "\n",
    "            # Ensure to take the mean if it's a list\n",
    "            if isinstance(precision, list):\n",
    "                precision = sum(precision) / len(precision)\n",
    "            if isinstance(recall, list):\n",
    "                recall = sum(recall) / len(recall)\n",
    "            \n",
    "            # Reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            mean_iou_metric.reset()\n",
    "            precision_metric.reset()\n",
    "            recall_metric.reset()\n",
    "            \n",
    "            metric_values['dice'].append(dice)\n",
    "            metric_values['iou'].append(mean_iou)\n",
    "            metric_values['precision'].append(precision)\n",
    "            metric_values['recall'].append(recall)\n",
    "            \n",
    "            if dice > best_metric:\n",
    "                best_metric = dice\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_segmentation2d_array.pth\")\n",
    "                print(\"Saved new best metric model\")\n",
    "            \n",
    "            print(\n",
    "                f\"Current epoch: {epoch + 1} current mean dice: {dice:.4f} best mean dice: {best_metric:.4f} at epoch {best_metric_epoch}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"MeanIOU: {mean_iou:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\"\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", dice, epoch + 1)\n",
    "            writer.add_scalar(\"val_mean_iou\", mean_iou, epoch + 1)\n",
    "            writer.add_scalar(\"val_precision\", precision, epoch + 1)\n",
    "            writer.add_scalar(\"val_recall\", recall, epoch + 1)\n",
    "            \n",
    "            # Plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            monai.visualize.plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            monai.visualize.plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            monai.visualize.plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
