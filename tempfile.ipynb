{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(tempdir):\n",
    "    \n",
    "    # Define paths to image and mask directories\n",
    "    image_dir = os.path.join(tempdir, \"image\")\n",
    "    mask_dir = os.path.join(tempdir, \"mask\")\n",
    "\n",
    "    # Read image and mask file paths\n",
    "    images = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "    masks = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "\n",
    "    if len(images) != len(masks):\n",
    "        raise ValueError(\"The number of images and masks must be the same.\")\n",
    "    \n",
    "    # Print the total number of samples in the dataset\n",
    "    total_samples = len(images)\n",
    "    print(f\"Total number of samples in the dataset: {total_samples}\")\n",
    "    \n",
    "    # define transforms for image and segmentation\n",
    "    train_imtrans = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True, ensure_channel_first=True),\n",
    "            ScaleIntensity(),\n",
    "            RandSpatialCrop((128, 128), random_size=False),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "        ]\n",
    "    )\n",
    "    train_masktrans = Compose(\n",
    "        [\n",
    "            LoadImage(image_only=True, ensure_channel_first=True),\n",
    "            ScaleIntensity(),\n",
    "            RandSpatialCrop((128, 128), random_size=False),\n",
    "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
    "        ]\n",
    "    )\n",
    "    val_imtrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "    val_masktrans = Compose([LoadImage(image_only=True, ensure_channel_first=True), ScaleIntensity()])\n",
    "\n",
    "    # define array dataset, data loader\n",
    "    check_ds = ArrayDataset(images, train_imtrans, masks, train_masktrans)\n",
    "    check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=True)\n",
    "    im, msk = monai.utils.misc.first(check_loader)\n",
    "    print(im.shape, msk.shape)\n",
    "    \n",
    "    # Display some raw images and their corresponding segmentation masks\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            idx = i * 2 + j\n",
    "            axes[i, j].imshow(im[idx].permute(1, 2, 0).byte().numpy())\n",
    "            axes[i, j].imshow(msk[idx].squeeze().byte().numpy(), alpha=0.5)\n",
    "            axes[i, j].axis('off')\n",
    "    plt.suptitle(\"Raw Images and Segmentation Masks\")\n",
    "    plt.show()\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    train_size = int(0.8 * total_samples)\n",
    "    val_size = total_samples - train_size\n",
    "    train_images, val_images = images[:train_size], images[train_size:]\n",
    "    train_masks, val_masks = masks[:train_size], masks[train_size:]\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = ArrayDataset(train_images, train_imtrans, train_masks, train_masktrans)\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.backends.mps.is_available())\n",
    "    \n",
    "    # create a validation data loader\n",
    "    val_ds = ArrayDataset(val_images, val_imtrans, val_masks, val_masktrans)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    # Display some augmented images and their corresponding segmentation masks\n",
    "    aug_images, aug_masks = next(iter(train_loader))\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            idx = i * 2 + j\n",
    "            axes[i, j].imshow(aug_images[idx].permute(1, 2, 0).byte().numpy())\n",
    "            axes[i, j].imshow(aug_masks[idx].squeeze().byte().numpy(), alpha=0.5)\n",
    "            axes[i, j].axis('off')\n",
    "    plt.suptitle(\"Augmented Images and Segmentation Masks\")\n",
    "    plt.show()\n",
    "\n",
    "    # Rest of the code remains the same\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model = monai.networks.nets.UNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=3,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "    \n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 2\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(10):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{10}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_images = None\n",
    "                val_labels = None\n",
    "                val_outputs = None\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                    roi_size = (128, 128)\n",
    "                    sw_batch_size = 4\n",
    "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), \"best_metric_model_segmentation2d_array.pth\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(\"/Users/nittin_murthi/Documents/VS_Code/MONAI-UNET/segmentation_data/malignant/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
